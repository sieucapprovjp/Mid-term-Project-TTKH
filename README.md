# Mid-term-Project-TTKH
# Optimization Algorithms Comparison: Adam vs. Genetic Algorithm

Dá»± Ã¡n nÃ y thá»±c hiá»‡n mÃ´ phá»ng vÃ  so sÃ¡nh hiá»‡u nÄƒng giá»¯a thuáº­t toÃ¡n tá»‘i Æ°u dá»±a trÃªn Gradient (**Adam Optimizer**) vÃ  giáº£i thuáº­t di truyá»n (**Genetic Algorithm - GA**) trÃªn hai hÃ m má»¥c tiÃªu kinh Ä‘iá»ƒn: **Rosenbrock** (Ä‘Æ¡n cá»±c trá»‹) vÃ  **Rastrigin** (Ä‘a cá»±c trá»‹).

## ğŸ“‹ Má»¥c lá»¥c
- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [Káº¿t quáº£ thá»±c nghiá»‡m](#káº¿t-quáº£-thá»±c-nghiá»‡m)
- [HÃ¬nh áº£nh minh há»a](#hÃ¬nh-áº£nh-minh-há»a)

## ğŸ“– Giá»›i thiá»‡u

- **Má»¥c tiÃªu:** TÃ¬m cá»±c tiá»ƒu toÃ n cá»¥c (Global Minima) cá»§a hÃ m sá»‘.
- **Input:** Äiá»ƒm xuáº¥t phÃ¡t chung $x_0 = [-1.0, 2.0]$.
- **HÃ m má»¥c tiÃªu:**
  1. **Rosenbrock:** Thung lÅ©ng háº¹p, hÃ¬nh Parabol. Global Min táº¡i $[1, 1]$.
  2. **Rastrigin:** Bá» máº·t gá»“ ghá», nhiá»u cá»±c tiá»ƒu Ä‘á»‹a phÆ°Æ¡ng. Global Min táº¡i $[0, 0]$.

## âš™ï¸ CÃ i Ä‘áº·t

YÃªu cáº§u mÃ´i trÆ°á»ng Python 3.x vÃ  cÃ¡c thÆ° viá»‡n:

```bash
pip install numpy matplotlib
